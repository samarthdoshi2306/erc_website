{% extends "erc/blog/BlogBase.html" %}
{% block blog %}
title      = meanshiftAlgo
heading    = Meanshift Algorithm for Image Processing
subheading = A very basic, yet essential, algorithm for removing noise and forming Clusters in an image.
category   = Information
tags       = Algorithms, Mean Shift Algorithm
author     = Dhruv Ilesh Shah
date       = March 24, 2016

//(DO NOT REMOVE THESE LINES)
//(WRITE YOUR BLOG BELOW FROM LINE 12)

<p><strong><u>Pre-requisites</u></strong> - Basic idea of matrices(wrt pixels), a <a href="https://en.wikipedia.org/wiki/Kernel_(image_processing)">kernel or convolution matrix</a>, local binary patterns, high-school statistics principles and <em>enthu</em>!
<img id="img1" src="/static/erc/assets/assets/meanshift-algorithm-for-image-processing/demo_org.png" alt="Original Image" /> <img id="img2" src="/static/erc/assets/assets/meanshift-algorithm-for-image-processing/demo_4.png" alt="Image after using the algorithm" /> <br />
One of the most common and important applications of Image Processing remains <em>Edge-Detection</em>. The ‘algorithm’ followed for <a href="https://en.wikipedia.org/wiki/Canny_edge_detector">Canny-edge Detection</a> is as follows:</p>

<ul>
  <li>Apply a suitable filter to smooth the image in order to remove the noise</li>
  <li>Find the intensity gradients of the image</li>
  <li>Apply non-maximum suppression to get rid of spurious response to edge detection</li>
  <li>Apply double threshold to determine potential edges</li>
  <li>Track edge by hysteresis: Finalize the detection of edges by suppressing all the other edges that are weak and not connected to strong edges</li>
</ul>

<p>As you can see, the most very first step involves filtering and removal of the noise. <br />
<strong>WHAT IS THIS <em>NOISE</em>?</strong>
In the sense used here, <em>noise</em> refers to subtle variations in pixel definitions, that may be recognised as an edge, but is most certainly not one. In the same sense as signals, it is unwanted in this purpose and needs to reduced.</p>

<h2 id="the-statistics">The Statistics</h2>
<p>The algorithm, in simple words, involves replacing each pixel definition with one obtained by applying the kernel on it - in general, forming a sort of mean application - which is similar to averaging out and minimising the noise.</p>

<p><img id="img3" src="/static/erc/assets/assets/meanshift-algorithm-for-image-processing/meanshift_fx.png" alt="Meanshift Principle" /></p>

<p>Here, <em>g</em> refers to the Kernel operation applied on each element Xi, where X is an assumed mean and <em>h</em> is a parameter called <u>resolution</u>. The obtained expression m(x) is referred to as the Mean Shift, on following this procedure for a large number of times, this m(x) converges to zero. We wish to minimise this m(x), without losing much information, so that further techniques of gradient can be applied for edge-detection. This is similar to <a href="http://mathworld.wolfram.com/JacobiMethod.html">Jacobi’s Method</a> of iteration.</p>

<h2 id="the-algorithm">The Algorithm</h2>
<p>Now, coming to the real application part of the algorithm, this method involves applying a suitable convulation matrix to the image matrix to smoothen out the edges. This matrix can be of various types, and optimised for better results. Some simple types include:</p>

<ol>
  <li>Flat Kernel (linear)</li>
  <li>Gaussian Kernel (exponential)</li>
  <li>Epanechikov Kernel (quadratic)</li>
</ol>

<p>The simplest of these is the Flat Kernel, in which the pixel’s value is changed to the averaged value of it’s surroundings, with equal weight to each pixel. <img id="img4" src="/static/erc/assets/assets/meanshift-algorithm-for-image-processing/flat_kernel.png" alt="Flat Kernel" /></p>

<p>A sample code for this algorithm, implemented in ‘MATLAB’,  is as follows:</p>

<figure class="highlight"><pre><code class="language-matlab" data-lang="matlab">	<span class="n">it</span> <span class="o">=</span> <span class="mi">10000</span><span class="p">;</span> <span class="c1">%set the number of iterations of the algorithm</span>
	<span class="k">for</span> <span class="n">k</span> <span class="o">=</span> <span class="mi">1</span><span class="p">:</span><span class="n">it</span>
    	<span class="k">for</span> <span class="nb">i</span> <span class="o">=</span> <span class="mi">2</span><span class="p">:</span><span class="n">nx</span><span class="o">-</span><span class="mi">2</span>
        	<span class="k">for</span> <span class="nb">j</span> <span class="o">=</span> <span class="mi">2</span><span class="p">:</span><span class="n">ny</span><span class="o">-</span><span class="mi">2</span>
            	<span class="n">Vt</span><span class="p">(</span><span class="nb">i</span><span class="p">,</span><span class="nb">j</span><span class="p">)</span> <span class="o">=</span> <span class="p">(</span><span class="n">V</span><span class="p">(</span><span class="nb">i</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span><span class="nb">j</span><span class="p">)</span> <span class="o">+</span> <span class="n">V</span><span class="p">(</span><span class="nb">i</span><span class="p">,</span><span class="nb">j</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="n">V</span><span class="p">(</span><span class="nb">i</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="nb">j</span><span class="p">)</span> <span class="o">+</span> <span class="n">V</span><span class="p">(</span><span class="nb">i</span><span class="p">,</span><span class="nb">j</span><span class="o">-</span><span class="mi">1</span><span class="p">))/</span><span class="mi">4</span><span class="p">;</span> <span class="c1">% Kernel Definition</span>
        	<span class="k">end</span>        
    	<span class="k">end</span>
    	<span class="n">V</span><span class="o">=</span><span class="n">Vt</span><span class="p">;</span>
	<span class="k">end</span></code></pre></figure>

<p>Here, V is the image matrix of ‘nx X ny’ and Vt is a dummy matrix of same size, used during the loop. The filter can be changed by altering the line marked as <em>Kernel Definition</em>.
Basically, the algorithm can be used to merge modes and generate clusters.</p>

<ul>
  <li><em>Modes</em>- Modes refer to the peaks in color intensities in the pixel map. When plotted, these are the peaks in ‘3D-plot’.</li>
  <li><em>Clusters</em>- Clusters refer to the groups of similarly defined pixels, ie, groups with similar color or compositon.</li>
</ul>

<p>As you can see in the images below, as the number of iterations increase, modes get merged and a cluser is formed.</p>

<p><strong>THE PARAMETERS:</strong> The alterable parameters include:
*‘it’ or the number of iterations. Increasing ‘it’ would increase the merge rate, but also increase the computational cost as number of iterations would increase. Hence, there is an optimised upper bound for this value.
<img id="img5" src="/static/erc/assets/assets/meanshift-algorithm-for-image-processing/Meanshift0.jpg" alt="Original Image - 2 modes" /> <img id="img6" src="/static/erc/assets/assets/meanshift-algorithm-for-image-processing/Meanshift100.jpg" alt="100 Iterations" /> <img id="img7" src="/static/erc/assets/assets/meanshift-algorithm-for-image-processing/Meanshift500.jpg" alt="500 Iterations" /></p>

<p>*‘h’ or resolution is a parameter used in the statistical definition. Since it is in the denominator, it can play a huge role in the smoothening effect as shown. In general, a large ‘h’ would mean faster convergence, larger clusters and more loss of information. This value can be tweaked as desired, for optimal results.
<img id="img8" src="/static/erc/assets/assets/meanshift-algorithm-for-image-processing/meanshift_H_org.png" alt="Original Image" /> <img id="img9" src="/static/erc/assets/assets/meanshift-algorithm-for-image-processing/meanshift_H_6.png" alt="h = 6" /> <img id="img10" src="/static/erc/assets/assets/meanshift-algorithm-for-image-processing/meanshift_H_16.png" alt="h = 16" /></p>

<p>For more such example, you can refer to <a href="https://www.inf.tu-dresden.de/content/institutes/ki/is/VORTRAG/Vortrag_Huong_Nguyen.pdf">this PDF</a>.</p>

<p><strong>ADVANTAGES</strong>
Comparing with other clustering algo K-means, it does not ASSUME any cluster etc. and the algo ensures that clusters are sorted automatically. Also, it is robust and works for any no. of (non-predefined) modes.</p>

<p><strong>DRAWBACKS</strong>
The iterative technique is highly redundant and computationally expensive; also, the method doesnt work well in free space (3D), as there may exist many local maximas that converge to optimas and mode isolation cannot be done.</p>

<p>This concludes the summary of an essential algorithm in the art of Image Processing. Hope you enjoyed it!</p>
<script>
  var images=[]
  function getURL(part){
    images={{blog|safe}}

    return images[part-1]
  };
  var i=1;
  for (i = 1; i <=8; i++) { 
        document.getElementById("img" + i).src ="/media/"+getURL(i); 
    }
  
</script>
{% endblock %}